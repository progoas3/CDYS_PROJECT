ğŸ“Š Pipeline Medallion: Credit Event Processing
Este proyecto implementa una arquitectura de datos tipo Medallion (Bronze, Silver, Gold) utilizando PySpark. El sistema simula la ingesta de eventos de crÃ©dito en tiempo real (Streaming) y procesa los datos a travÃ©s de diferentes capas para generar mÃ©tricas de riesgo y un reporte final de consistencia.

ğŸ—ï¸ Arquitectura del Proyecto
El flujo de datos se divide en las siguientes etapas:

Landing (SimulaciÃ³n): Un script genera micro-batches de datos en formato CSV a partir de una fuente maestra.

Bronze (Ingesta): Captura los datos de Landing, aÃ±ade metadatos de auditorÃ­a (timestamp, archivo origen) y garantiza la idempotencia evitando procesar el mismo batch dos veces.

Silver (Calidad): Limpia los datos, aplica reglas de negocio, estandariza estados de crÃ©dito y separa los registros errÃ³neos en una tabla de Cuarentena.

Gold (Negocio): Enriquece la informaciÃ³n con datos geogrÃ¡ficos y genera tablas agregadas para anÃ¡lisis de riesgos y cohortes.

Reporte: Genera un dashboard visual en HTML con el resumen del estado de los datos.

ğŸ“‚ Estructura de Carpetas
Plaintext
project/
â”œâ”€â”€ data/                   # Almacenamiento de capas (Parquet/CSV)
â”‚   â”œâ”€â”€ raw_input/          # Fuente maestra (.csv)
â”‚   â”œâ”€â”€ landing/            # Zona de llegada de batches
â”‚   â”œâ”€â”€ bronze/             # Capa de datos crudos persistidos
â”‚   â”œâ”€â”€ silver/             # Capa de datos limpios y vÃ¡lidos
â”‚   â””â”€â”€ gold/               # Capa de productos de datos enriquecidos
â”œâ”€â”€ scripts/                # LÃ³gica de procesamiento PySpark
â”‚   â”œâ”€â”€ simulate_streaming.py
â”‚   â”œâ”€â”€ bronze.py
â”‚   â”œâ”€â”€ silver.py
â”‚   â”œâ”€â”€ gold.py
â”‚   â””â”€â”€ report.py
â”œâ”€â”€ main.py                 # Orquestador del pipeline
â””â”€â”€ report_final.html       # Resultado final visual
ğŸš€ Instrucciones de EjecuciÃ³n
Para un funcionamiento Ã³ptimo en Windows y para simular un entorno real de streaming, se recomienda ejecutar el sistema en dos terminales:

Paso 1: Iniciar la Ingesta (Terminal 1)
Este script simula la llegada continua de datos a la carpeta landing.

Bash
python project/scripts/simulate_streaming.py
Paso 2: Ejecutar el Pipeline (Terminal 2)
Mientras la Terminal 1 estÃ¡ corriendo, ejecuta el orquestador principal que procesarÃ¡ todas las capas de forma lineal:

Bash
python project/main.py
ğŸ› ï¸ TecnologÃ­as Utilizadas
Lenguaje: Python 3.11+

Procesamiento: Apache Spark (PySpark)

VisualizaciÃ³n: Plotly (Reporte HTML)

GestiÃ³n de Archivos: Pathlib / OS

ğŸ” Reglas de Calidad (Capa Silver)
loan_id: No nulo.

principal_amount: Debe ser mayor a 0.

interest_rate: Debe estar entre 0 y 1.

loan_status: Debe pertenecer al catÃ¡logo oficial (ACTIVE, DELINQUENT, etc.).

DeduplicaciÃ³n: Basada en la llave natural (loan_id, event_time, event_type).